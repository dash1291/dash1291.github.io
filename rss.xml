<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Ashish Dubey's Blog]]></title><description><![CDATA[Experiments with tech and their record on the internet]]></description><link>https://ashishdubey.xyz</link><generator>RSS for Node</generator><lastBuildDate>Wed, 30 Jan 2019 21:23:24 GMT</lastBuildDate><item><title><![CDATA[Notes on Agile Testing]]></title><description><![CDATA[I recently started reading  Agile Testing book  and while I was learning a bunch of things and taking notes I figured it’d be nice to also…]]></description><link>https://ashishdubey.xyz/2019/01/31/agile-testing.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2019/01/31/agile-testing.html</guid><pubDate>Tue, 29 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I recently started reading &lt;a href=&quot;https://books.google.co.in/books/about/Agile_Testing.html?id=68_lhPvoKS8C&amp;#x26;redir_esc=y&quot;&gt;Agile Testing book&lt;/a&gt; and while I was learning a bunch of things and taking notes I figured it’d be nice to also share these notes here. Mostly, in order to make it easy for myself to give to someone, my version of the summary of the book. It might be work in progress for a while, but hopefully covering something helpful.&lt;/p&gt;
&lt;h2&gt;On agile testing mind-set&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Creativity, openness to ideas, willingness to take on any task or role, focus on the customer and a constant view of the big picture are some components of the agile testing mind-set.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Agile testing mind-set is one that is results-oriented, craftsman-like, collaborative, eager to learn, and passionate about delivering business value.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some of the ten principles for agile testers -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;continuous feedback&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;keeping testing and tooling simple&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;retrospective: continuous improvement and responding to change&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;customer first&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To keep things simple doesn’t mean keep it easy. It means “just enough”. Agile testing should start with the lightest weight possible and whatever does the job. Tools can be as simple as a spreadsheet or a checklist. Smoke tests might be enough for a business facing test suite.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;On agile testing practices&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;It’s upto the customers (business) to decide what level of quality they want to pay for (including performance and security). The testers should support this level of testing through information (For making decisions) and tooling to achieve the required testing.&lt;/li&gt;
&lt;li&gt;Impediment backlog of things that prevent agile team members from being at their productive best.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;On building an agile testing team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Agile teams is a good place for testers, because true agile teams are all about repeatable quality.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A job description for the agile tester should include cross functional experience -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;An example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Experience writing UI tests and helping business experts define requirements&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Experience writing SQL queries&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At least one year of experience working with a programming / scripting language&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ability to use unix&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Experience communication with programmers and product owners&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Face-to-face communication has no substitute. Agile development depends on constant collaboration. Like other agile team members, the people doing testing tasks will continually seek out customer and technical team members to discuss and collaborate&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[An amateur quest to generative music]]></title><description><![CDATA[In the last few months, I’ve spent quite a bit of spare time and effort in learning about music theory and sound engineering. This includes…]]></description><link>https://ashishdubey.xyz/2018/11/18/generative-music.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2018/11/18/generative-music.html</guid><pubDate>Sun, 18 Nov 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In the last few months, I’ve spent quite a bit of spare time and effort in learning about music theory and sound engineering. This includes learning enough about harmonics to be able to play simple musical motifs on an electric guitar, understanding basics of sound synthesis and processing. On top of this, I also got exposed to electronic art that is created on the basis of systems and processes rather than being written as a finite progression of harmonics. Incase you’re wondering what I’m talking about look up Brian Eno, Steve Reich, Terry Riley and related artists.&lt;/p&gt;
&lt;p&gt;So, I’ve been interested in generative art of all kinds for a long time. And I gained some momentum after being exposed to all the information mentioned previously and really good hands-on material like &lt;a href=&quot;https://teropa.info/blog/2016/07/28/javascript-systems-music.html&quot;&gt;this extensive article&lt;/a&gt; which set things straight on how these systems can be built programmatically. One of my recent hacks on these lines lives at &lt;a href=&quot;https://noisescape.glitch.me&quot;&gt;noisescape.glitch.me&lt;/a&gt;. This is a simple systems music experiment written in JavaScript using WebAudio API. It’s a combination of &lt;a href=&quot;https://en.wikipedia.org/wiki/Phase_music&quot;&gt;phase music&lt;/a&gt; generated using xylophone notes playing in two loops and some piano notes looping at different intervals.&lt;/p&gt;
&lt;p&gt;I’m going to break down the experiment into the different components and write about them in the following paragraphs. This is an amateur classification so please let me know if I miss a detail or overstate a few.&lt;/p&gt;
&lt;h2&gt;Harmonics&lt;/h2&gt;
&lt;p&gt;In this part we’ll talk about the musical structure of the experiment. There may be a bunch of music theory concepts which may not fit in the scope of this article, hence linked to external resources so that you can read about them.&lt;/p&gt;
&lt;p&gt;It was important to make the generated music sound nice but there is also only so much that can be done and should be done here. It’s more about the patterns which the system creates with the combination of simple loops. So in order to make the generated output not sound bad, all of the notes played in this system are taken from the C# Major arpeggio. If you play music, you might already know that an &lt;a href=&quot;https://en.wikipedia.org/wiki/Arpeggio&quot;&gt;arpeggio&lt;/a&gt; refers to the notes in a chord played in any order. This set of notes is used in two ways -&lt;/p&gt;
&lt;p&gt;First, for creating a simple melody based on 3 notes and running it in a loop that repeats after every &lt;a href=&quot;https://en.wikipedia.org/wiki/Bar_(music)&quot;&gt;3/4th measure&lt;/a&gt;. These loops start together in phase and as the music progresses they phase changes and new patterns emerge. For those who can read music, I included a pitch sheet below for indulgence -&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/f524476283c5e580ef8bedf8ef0448aa/7b4ad/xylosheet.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block;  max-width: 557px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 39.85637342908438%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABcSAAAXEgFnn9JSAAABV0lEQVQoz62SyYoCQQyG+1G9+AB68uIbKHjvg9tJRC+KuIAoNgguiKK40S4oCOKCCoK4fE4CDs0wc5sfUkUqXcmXVBt86fF4cDqdOB6PrNdr7ve7HPN6vdSez6ea0/9IfKcMWQqFArPZjF6vRyqV4nw+a9B58eflT3JnEdk1oVAtFgt+k8Ta7Tbb7Vb92+2mxf+ScTgcSKfTJJNJ+v0+iUSCyWRCs9lkuVySy+UIBAL6TTgcplwuY5qmAsznczUpKufj8RhjOBzicrnIZDLUajU8Hg+NRoNgMEgsFtO5jkYjBoPBt9m2zWazoVgsks1mqVarRCIRSqUSRqfTwefzEQqFsCwLr9fLdDoln88rSTQaxe/343a7abVaSi+drFYr7aZSqSjZh964Xq/E43FtUWi63a7uMrN6va5FhFiSCJXE9vu9mvi73U7/EGldxqePIkSXy4X/0Bvj3T8jLSGFUAAAAABJRU5ErkJggg==&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;Xylophone sheet&quot; title=&quot;&quot; src=&quot;/static/f524476283c5e580ef8bedf8ef0448aa/7b4ad/xylosheet.png&quot; srcset=&quot;/static/f524476283c5e580ef8bedf8ef0448aa/25bfb/xylosheet.png 148w,
/static/f524476283c5e580ef8bedf8ef0448aa/b58bd/xylosheet.png 295w,
/static/f524476283c5e580ef8bedf8ef0448aa/7b4ad/xylosheet.png 557w&quot; sizes=&quot;(max-width: 557px) 100vw, 557px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;Secondly, we use this arpeggio to create a foreground piano line with 7 notes looping at different intervals. Since they loop at different intervals, the notes would play in various combinations for a long time.&lt;/p&gt;
&lt;p&gt;Here are all the notes that are used -&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;G# and C# in octave 3&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;G#, C#, F, F# and A# in octave 4&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Since these notes form a major chord, they are very consonant with each other. Consonance and dissonance are music theory concepts which you can learn better from &lt;a href=&quot;https://en.wikipedia.org/wiki/Consonance_and_dissonance&quot;&gt;other resources&lt;/a&gt;. In the context of this experiment, this piece of information helps because we can be sure that when we play any of these notes in any order or even together (in either the 3 beat long xylophone line or the piano loops), they’re going to sound good. And the sound’s tonic centre would be is C# major. However, just to make the piano line a little more interesting, I picked another note from outside of the arpeggio but still not dissonant with other notes.&lt;/p&gt;
&lt;p&gt;Playing all of these notes, and other musical aspects like timings and measures in this experiment are achieved with &lt;a href=&quot;https://tonejs.github.io&quot;&gt;Tone.js&lt;/a&gt; library which is a great abstraction over WebAudio API in the browser.&lt;/p&gt;
&lt;h2&gt;Sound design&lt;/h2&gt;
&lt;p&gt;We’ve talked about what sounds we play in this experiment, but how we play them is as important. This is actually where much of the magic happens. The texture of sound and the machinery that keeps the music ever changing is discussed here.&lt;/p&gt;
&lt;p&gt;I wanted to generate sounds of real instruments so that the output can be related to by variety of listeners. &lt;a href=&quot;https://nbrosowsky.github.io/tonejs-instruments/&quot;&gt;This library&lt;/a&gt; made it really easy for me to be able to generate sounds like of real instruments. I didn’t have to deal with hooking up each instrument’s recorded samples into Tone.js myself. I used the already available xylophone and piano samples which are hosted by the author themselves.&lt;/p&gt;
&lt;p&gt;Using Tonejs instruments’ API I wrote down two synth nodes playing Xylophone notes (which are chosen as mentioned above in Harmonics). These synths nodes are connected with a &lt;a href=&quot;https://tonejs.github.io/docs/r12/Gain&quot;&gt;Gain node&lt;/a&gt; with gain level = 0.25 which means the xylophone loops are played at 25% volume. Each of the loops are connected to &lt;a href=&quot;https://tonejs.github.io/docs/r12/Panner&quot;&gt;Panner nodes&lt;/a&gt; which routes the sound of each loop through left and right channels giving it a stereo stage. As the phase increases this leads to interesting sound effects which may seem like echo or ping-pong at different times.&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/db576e3ab917dce474607aae7749c446/9f6e6/xyloloops.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 30.916666666666664%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAAsTAAALEwEAmpwYAAABB0lEQVQY021PWW+EIBD2//+hpn1r2td2D9cTQVFX8cADU1wVsNMjzT50Mhlg8l1Yw9Cxsqjrqu+5Uhs8u65NEhL4zrbNsxQ3Oc3zhHGAAidPyThw+3wIfZfG2AKc77nFNWes6DqOUIjC4Hw6Ht7fjNFCjCBHafz68uzYJ89zLvbx6fHBdS8EI4smMSERMCcxbutSVYyxEsY0iX3ftdZSfmzryr7WhRADb9sIhSAHAYFMUprUVQVo8MmytGnqsizrpoYgUkql1H5XWiuttmW5QVsRQmBeFldKE+g8y/I8Ixinaco5/+OY74IDrj8TPmWBT98BrAUrEIPVuq6QEwLv/5T5lTHaaPUJnX5NOuke5YAAAAAASUVORK5CYII=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;xylophone setup&quot; title=&quot;&quot; src=&quot;/static/db576e3ab917dce474607aae7749c446/fb8a0/xyloloops.png&quot; srcset=&quot;/static/db576e3ab917dce474607aae7749c446/1a291/xyloloops.png 148w,
/static/db576e3ab917dce474607aae7749c446/2bc4a/xyloloops.png 295w,
/static/db576e3ab917dce474607aae7749c446/fb8a0/xyloloops.png 590w,
/static/db576e3ab917dce474607aae7749c446/526de/xyloloops.png 885w,
/static/db576e3ab917dce474607aae7749c446/fa2eb/xyloloops.png 1180w,
/static/db576e3ab917dce474607aae7749c446/9f6e6/xyloloops.png 1200w&quot; sizes=&quot;(max-width: 590px) 100vw, 590px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;While piano notes sounded great, I felt like they could be smoothened up a little to meld as slowly playing background music while the xylophone phase varies. For that I added a &lt;a href=&quot;https://tonejs.github.io/docs/r12/Freeverb&quot;&gt;Reverb node&lt;/a&gt; to the piano synth. This seemed to do the trick as the signal decays slowly. &lt;a href=&quot;https://en.wikipedia.org/wiki/Reverberation&quot;&gt;Reverberation&lt;/a&gt; generally adds a feeling of spaciousness to a sound that is run through it.&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/41bb022f1749d719263e416bf8f93e8b/ad082/pianosetup.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 34.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAAsTAAALEwEAmpwYAAABQElEQVQY04WQyW6DQAyGef83adVzm/aS0ES9tBEJW0pYEpbAsA1rYIAZpk6jnvvLskaW/89jC5zzeZ57ECE9GYaRth1p2r6s2yTDcZpHceqcPcs5m5ZjQ7ZPxtHWDoas6sJEqSTtXNctyypO0qpuAEfGSVH1b8OEvJNVQKA4DULknFwLzCZAPAghDEPDMDDOYXSW50CZZ46L8mXxut587BXt4fEJnF4QLsX18+LtcyttJSjrlygWoLuqqqIokiQpy9L3/bquUYTOrqdqh6NpG0cruCBZ0VfierkSd3tFVjXxfZPlpYAQiiKU4wJjnGVZ13X8V5TSYZxG2IrNjPM4yTz/AlsA62srwez2SgTGZui7n40xdnfCm/8JzCNlXT8kKYav+kEIlKJqmrYT+H9i880/0VsMI+vJ2JGxbrq6uf4AG2iAUVYGdngAAAAASUVORK5CYII=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;piano setup&quot; title=&quot;&quot; src=&quot;/static/41bb022f1749d719263e416bf8f93e8b/fb8a0/pianosetup.png&quot; srcset=&quot;/static/41bb022f1749d719263e416bf8f93e8b/1a291/pianosetup.png 148w,
/static/41bb022f1749d719263e416bf8f93e8b/2bc4a/pianosetup.png 295w,
/static/41bb022f1749d719263e416bf8f93e8b/fb8a0/pianosetup.png 590w,
/static/41bb022f1749d719263e416bf8f93e8b/526de/pianosetup.png 885w,
/static/41bb022f1749d719263e416bf8f93e8b/ad082/pianosetup.png 900w&quot; sizes=&quot;(max-width: 590px) 100vw, 590px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;As these notes repeat, they tend to play in various combinations and patterns, which are hard to predict in the beginning. This makes the generated music feel like it’s repetitive but something is always changing.&lt;/p&gt;
&lt;h2&gt;Noise interaction&lt;/h2&gt;
&lt;p&gt;Another variation that happens to this looping music is controlled by the environment making this system even more unpredictable. This variation is based on the noise levels in the environment. To achieve this an &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode&quot;&gt;Analyser node&lt;/a&gt; is used to obtain &lt;a href=&quot;http://www.elvers.us/perception/soundWave/&quot;&gt;frequency domain data&lt;/a&gt; of the default input and the values are averaged over the entire range to give an overall noise level. Although not accurately the noise level as it’s prone to discounting few frequencies playing at high levels. Let’s see if I can do better in future.&lt;/p&gt;
&lt;p&gt;Anyway, &lt;strong&gt;&lt;em&gt;The noise level controls the speed at which one of the loops plays.&lt;/em&gt;&lt;/strong&gt; This means as the noise in background increases, the loops phase out further and with a decrease, the loops come back in phase.&lt;/p&gt;
&lt;p&gt;The coolest part about this hack is that it has given me a mental framework to think over when trying to build procedural art in future. I can not only fantasize about creating something but I know how to proceed, which actually results in more ideas. It’s a circle. Not sure what exactly follows from here, but definitely a string of more experiments. If you’re a musician (especially electronic) or a technologist interested in music, I’d love to hear your thoughts on this.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Web of audio visualization devices]]></title><description><![CDATA[One of the last tweets I read towards the end of 2017 was about the excitement about WebUSB in the upcoming year. WebUSB left a powerful…]]></description><link>https://ashishdubey.xyz/2018/04/01/webaudio-viz-webusb.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2018/04/01/webaudio-viz-webusb.html</guid><pubDate>Sun, 01 Apr 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;One of the last tweets I read towards the end of 2017 was about the excitement about WebUSB in the upcoming year. WebUSB left a powerful first impression on me, especially with the promise of how it could take the web forward as a platform. With this new power, web engineers can build applications which can talk directly with USB devices. Since these applications would be written in Javascript and run as web applications, expertise in writing system specific software won’t be needed.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Here is what I am most excited about for the web in 2018. &lt;br&gt;&lt;br&gt;Web USB&lt;br&gt;&lt;br&gt;The moment companies realize their custom hardware no longer requires per platform device drivers and instead can be browser based is going to open the flood gates.&lt;/p&gt;&amp;mdash; Sam Saccone (@samccone) &lt;a href=&quot;https://twitter.com/samccone/status/945020246242377728?ref_src=twsrc%5Etfw&quot;&gt;December 24, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;Every such promise comes with a myriad of new possibilities. If you followed my blog, not long ago, I wrote about my newly lost-and-found excitement towards building audio visualizations (read it &lt;a href=&quot;https://ashishdubey.xyz/2017/12/27/waves-planes.html&quot;&gt;here&lt;/a&gt;). What I haven’t ever written on my blog is my love towards LEDs. You can already see where this is going.&lt;/p&gt;
&lt;p&gt;I’ve wanted to play with RGB LEDs for a very long time, and the possibility of an educational hack got me pumped. I stumbled upon &lt;a href=&quot;http://www.instructables.com/id/Bitbanging-step-by-step-Arduino-control-of-WS2811-/&quot;&gt;WS2812 addressable LEDs&lt;/a&gt;. I can’t fully describe here what addressable RGB LEDs are - but in a nutshell these LEDs are stuck to a circuit to which you can pass a timed signal to set the intensity of a particular color (R,G or B). It’s even possible to hook up more of these little circuits and control a whole array of LEDs with just one input. All you need is a perfectly timed signal to light up a particular LED with a particular color.&lt;/p&gt;
&lt;p&gt;While I was waiting for my LEDs, I already had an Arduino board to play with. Like every other new thing I start to play with, I forked the example project, and tried to make changes to it to understand how it all worked together. This was also the time when I couldn’t wait for my WS2812 LEDs and decided to hook up some of my WebAudio code with the WebUSB example project. The result was poor man’s beat detection driving my Arduino’s onboard LED.&lt;/p&gt;
&lt;p&gt;When I finally had my 4x4 matrix of WS2812 LEDs, a soldering kit, and mounting impatience to put everything together, I built my device, and was ready to start coding. After some amount fiddling with arduino code which read bytes from the USB port, and the JS code which fed into arduino the bytes representing audio levels at different frequencies (as in spectrum analyzer), I was beginning to see my new device in action. And, this is what it looked like -&lt;/p&gt;
&lt;style&gt;
    .embed-container {
        position: relative;
        padding-bottom: 56.25%;
        height: 0; overflow: hidden;
        max-width: 100%; height: auto;
    }
    .embed-container iframe, .embed-container object, .embed-container embed {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }
&lt;/style&gt;
&lt;div class=&quot;embed-container&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/262706101&quot; frameborder=&quot;0&quot; webkitAllowFullScreen mozallowfullscreen allowFullScreen&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;Here is the summary of what happens -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A webpage is opened which listens to the audio and analyzes it using WebAudio&lt;/li&gt;
&lt;li&gt;Audio levels at certain frequencies are sent to Arduino over WebUSB. Each byte represents audio level at a particular frequency.&lt;/li&gt;
&lt;li&gt;Each input byte read from the serial input by Arduino is used to light up a particular column that represents an audio frequency.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I’ve put the code on Github &lt;a href=&quot;https://github.com/dash1291/ws2812-audio-viz&quot;&gt;here&lt;/a&gt;, in case anyone wants to have a look. A big shoutout to the authors of the amazing &lt;a href=&quot;https://github.com/adafruit/Adafruit_NeoPixel&quot;&gt;Neopixel library&lt;/a&gt; that makes it really easy to play with these little WS2812 LEDs by hiding away low-level details of controlling the AVR. This turned out to be quite a fun experiment and developed my further interest in developing web apps and more so, devices, which could work together. And it’s really so easy.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Being a volunteer at QCon]]></title><description><![CDATA[Earlier this month I got the opportunity to attend QCon in London. This was my first time at QCon, which was also the first of its kind of…]]></description><link>https://ashishdubey.xyz/2018/03/25/qcon-volunteer.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2018/03/25/qcon-volunteer.html</guid><pubDate>Sun, 25 Mar 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Earlier this month I got the opportunity to attend QCon in London. This was my first time at QCon, which was also the first of its kind of conferences for me. Most of the conferences I’ve attended before were community driven conferences like PyCon, RootConf, etc. Because I’ve always been to these conferences where people usually talk about open source software and not always processes or tools used for running the business at big companies, I was expecting less fun but was curious at the same time.&lt;/p&gt;
&lt;p&gt;Several tracks at the conference were around reliability and observability of large scale systems. Covering these subjects definitely holds importance at a conference intended for experienced engineers rather than hackers straight out of school and as a young engineer attending QCon for the first time, I could absolutely feel the difference. At Grofers, as we grow in business and team size, we face problems around running software on a larger scale. Engineering teams like us, working to help business grow, are constantly challenged to ship fast and often. Lot of people who were at QCon have either started facing these problems in recent times or have already solved these problems in their settings. From that perspective, it was good to hear from others facing similar problems and how they solved them. One of the major themes talked about at the conference was observability of software, as a practice of building reliable production systems. There was a big heap of one line sofware wisdom nuggets that I encountered at the conference, but I can easily pick one out. One that was thrown out by &lt;a href=&quot;https://twitter.com/mipsytipsy&quot;&gt;Charity Majors&lt;/a&gt; -&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Nines don’t matter if users aren’t happy&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It kind of highlights how the ability to design systems which are easily debuggable in production takes a backseat, when all infrastructure and reliablity efforts are driven by the uptime of services. There are a few things that we’ve been trying, or aspiring to do as an engineering team at Grofers to achieve that ability, so it was great to talk to several people and exchanging thoughts.&lt;/p&gt;
&lt;p&gt;While it was my first time at a conference like QCon, it was also my first time volunteering at a large conference. I’ve organized local meetups and a small city level conference before, so I was expecting way too much work, and probably less time for being able to actually grasp the content at the conference. However, everything was so well co-ordinated, thanks to the QCon staff and the volunteers who turned up in a decent number, that all volunteers got their fair share of the conference. They could attend talks which they were interested in, connect with the speakers, sponsors and other attendees and really be able to take away learnings from the conference like anyone else present there. Not to forget that volunteering seems to be a great way to contribute to a conference if you’re not an organizer or speaker. You are always involved and on the move, and because of that you also get a chance to interact with way more people than a normal attendee can (also, for free!). All of this made my first experience of volunteering really fulfilling and has got me excited for any other volunteering opportunities that I may get in future.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Core dumps for debugging web apps]]></title><description><![CDATA[Core dumps  have a history of being used for debugging earliest computers. In this post’s context, core dump is not a dump of all register…]]></description><link>https://ashishdubey.xyz/2018/01/28/web-core-dumps.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2018/01/28/web-core-dumps.html</guid><pubDate>Sun, 28 Jan 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Core_dump&quot;&gt;Core dumps&lt;/a&gt; have a history of being used for debugging earliest computers. In this post’s context, core dump is not a dump of all register values, memory, cache, etc of a CPU but more high level as state of my web application. It’s much high level as in the contents are different but the philosophy is the same - having a snapshot of the machine or software at the time of failure so that it could be investigated for the possible cause.&lt;/p&gt;
&lt;p&gt;At Grofers, we have a react application and we’re using redux to maintain state of the application in one magnificent object. This object is the source of truth for most of the rendering and behavior of the application. Apart from this state, there are local storage and cookies, containing bits of state, which is mostly a copy of subsets of the main Redux state.&lt;/p&gt;
&lt;p&gt;Now at any given point of time, if you copy the Redux state from one browser to another you can expect to pretty much replicate the application behavior. But there could be some bits in the local storage or cookies which might still conjure different results on different machines. To address that, if you replicated local storage and cookies as well, you’re pretty much done.&lt;/p&gt;
&lt;p&gt;I’ve pondered over the idea of using core dump of an application to debug it since the day I got introduced to it. Quite recently, I had an opportunity, in the form a bug which only happened on my machine. There was a UI element which should not show up for any user, given a set of actions taken by the user. With the same set of actions the UI element was showing up on my screen. Given that I knew how the application works, it would have been very easy for me to find out exactly what was wrong, but being able to replicate the bug on others’ machines seemed like a better problem to solve first.&lt;/p&gt;
&lt;p&gt;To quickly validate the method, I used the crude way of copying the state, and cookies from my erroneous browser session and pasted it in my server’s response, which would make sure the same state and cookies get to all of the clients. After replicating all of the state, I was actually able to replicate the bug. Once replicated, quick inspection into the difference between the corrupt state and the working state helped me tracked down a cookie that was causing this. This cookie was used to decide whether or not to show the UI element in question. A new change in the code somehow didn’t consider the case of stale cookies because of which saw this undesired behavior.&lt;/p&gt;
&lt;p&gt;The crude way worked, but ideally I’d like this to be easier. For just engineers, having a browser extension or something, which would capture all of this state and allow me to easily export the dump for someone else to import and replicate the application state. For an expanded set of users, something as simple as Report a Bug action on the website achieving the similar result should be even better.&lt;/p&gt;
&lt;p&gt;In a way being able to capture the snapshot of the application is about capturing the context of the application, detailed enough to predict the application behavior. Being able to replicate weird bugs by transferrable context, is an extremely powerful tool for debugging. People have used such tools for debugging in all kinds of applications, like using Dtrace or using &lt;a href=&quot;https://www.joyent.com/blog/mdb-and-node-js&quot;&gt;MDB&lt;/a&gt; for Node.js. Everyone puts enough monitoring and reporting for their application, but capturing the right context and in a consumable manner is what is missing at times. And that renders all the monitoring and reporting useless.&lt;/p&gt;
&lt;p&gt;So how do we get there? How do we capture the context? What should we capture? How should we share it across? There are services which integrate with your web app to capture logs on the console, network requests, and any other contextual data that you may want for debugging your app. Apps like InstaBug, etc. There is LogRocket. It can be as simple as Report a Bug button which captures all the data that an engineer might need to debug the application. Whatever you use you need to make sure that it’s easy to change what data you may need to capture, when you want to capture. etc The last thing you want to do is start using another tool with the promise of easier debuggability but end up at zero because you cannot use the tool the way you’d want.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Thoughts on software performance]]></title><description><![CDATA[I love building software and in recent times something I’ve specifically loved about software is making it perform faster. Performance is a…]]></description><link>https://ashishdubey.xyz/2017/12/30/thoughts-software-perf.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2017/12/30/thoughts-software-perf.html</guid><pubDate>Sat, 30 Dec 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I love building software and in recent times something I’ve specifically loved about software is making it perform faster. Performance is a feature, an afterthought, an art, and so much people claim it to be. Lot has been said and done in this area of software engineering.&lt;/p&gt;
&lt;p&gt;If I have to reflect on what I’ve learnt about performance of software, I will majorly focus on the role that it plays in driving the experience of using a software and also the basic principles behind improving software performance.&lt;/p&gt;
&lt;p&gt;Now in recent years, I’ve spent some good amount of time on improving software performance. It was improving remote streaming performance at Browserstack and web performance at Grofers. Althought, the systems and the ways to make them perform better were quite different in both the cases, but a bunch of things remained the same.&lt;/p&gt;
&lt;p&gt;One thing is performance improvement should be a cycle of measurement and implementation. You need to spend time in both the states to figure out what to implement next and obtain enough data to know when to stop. Measurement should give you insights of how your perf experiments have improved the experience for your users. Measurement should also give you enough information to determine bottlenecks in your system so you can attack the right problem.&lt;/p&gt;
&lt;p&gt;Another thing I learned was that you should understand your system well so that you can decide what might work best for your system. Performance best practices are great but you combine the contextual knowledge of your system and the best practice to determine the best hack that will bring you closer to your performance goal. At times, best practices don’t even apply fruitfully on your system and you might need to do unconventional hacks to improve performance.&lt;/p&gt;
&lt;p&gt;I realized this especially while improving the streaming performance at a point when best practices were in rarity. Not because there were not enough best practices for improving streaming performance in general, but this was after we applied best practices which were applicable for our system. And after that we were left alone chilling with our knowledge of the system and then we had to go brothers in arms for finding ways to improve the rate at which the video frames travelled from our data centers to the users’ browsers. Now one of the most effective ways in which we tried to achieve our goal involved working on network equipment rearrangement in our data center, leading to better quality video streams. Now this wasn’t something that we could find in the book of best practices.&lt;/p&gt;
&lt;p&gt;Similarly, so many times at Grofers, we improved perceived performance of our website either by optimizing just the critical product flow. For instance, we are trying out ways in which we can make the website usable with smallest possible JavaScript and CSS, and without waiting for the third-party libraries that make up the foundation of our website, which involves React. Again, this was something that was very contextual for our website, which would allow our users to be able to use our site with less waiting. And actually that’s right there, the best practice that applies universally in all systems. Performance is a feature that improves user experience. And that’s the goal everyone is to be chasing - improving the user experience.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Waves and planes]]></title><description><![CDATA[I recently read  Stephen Boyer’s post titled “My unusual hobby”  and resonated with much of the expressed thought - the pleasure of…]]></description><link>https://ashishdubey.xyz/2017/12/27/waves-planes.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2017/12/27/waves-planes.html</guid><pubDate>Wed, 27 Dec 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I recently read &lt;a href=&quot;https://www.stephanboyer.com/post/134/my-unusual-hobby&quot;&gt;Stephen Boyer’s post titled “My unusual hobby”&lt;/a&gt; and resonated with much of the expressed thought - the pleasure of programming as a recreational activity. As I grow up as a software engineer, I’ve observed for most of the fellow engineers that programming appears like a stressful activity and writing code that barely anyone cares much about doesn’t really fit the general idea of having fun.&lt;/p&gt;
&lt;p&gt;I’m another one who loves writing code for a variety of hobby projects. These aren’t projects aiming to make world a better place or anything, but just trying to recreate or create something that fascinates me. One class of such hacks is creating audio visualizations.&lt;/p&gt;
&lt;p&gt;There is history to why I derive fun out of things moving with sound. The first set of audio visualizations I worked on were part of an audio player I wrote a while ago in Visual Basic. That was an attempt to recreate something like Winamp back in the day, and I have to say it’s still one of my most memorable projects ever. I did not understand much about sine waves, audio frequency response, and everything else but those were the days of scavenging the internet for code snippets, trying to understand them enough, and tweak them to make them work. That part though, is still much the same.&lt;/p&gt;
&lt;p&gt;Although, I attempted to create audio visualizations a bunch of times in recent years but almost always the lack of concept of an apt application to contain my visualizations has shot the motivation down. Reading about recent WebAudio developments gave me some ideas. When a powerful platform is present everywhere, it gives it’s developers great power when they think of building an application. Friction produced by worrying about the platform capabilities and distributing the applications is gone. That’s what I love about web as a platform.&lt;/p&gt;
&lt;p&gt;Noisetab is the project that got me back into the visualizations game again. The fact that I could use WebAudio to build visualizations meant I could build web apps or browser extensions around audio visualizations. Noisetab is a Chrome extension with two basic audio visualizations - spectrum analyzer and the frequency domain oscilloscope. I could not contain my itch to build something different so over the next few days, I worked on another visualization which I called circular. This might look like a variation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/dash1291/noisetab/blob/master/tab.js#L71&quot;&gt;The code&lt;/a&gt; can pretty much explain how Circular is rendered. In the scope of this post, I’ll set the context on how audio parameters affect the rendering. In the visualization, you’ll notice a bunch of things reacting to the audio response - length and color of the bars along the circle and the radius of the circle. The length of each bar along the circle changes proportionally with the audio response at a particular frequency and red channel of the color changes similarly. The radius of the circle is the average of audio response over a range of low frequencies. That was the closest I could get to very basic beat detection.&lt;/p&gt;
&lt;p&gt;Circular turned out great. This was when I decided I’m going to try out 3D next. This was also an opportune moment to try out 3D stuff on web. Three.js came out as a nice way to try this out as you don’t need to understand OpenGL/WebGL to use the GPU for playing with the pixel geometry and the colors. The effect I wanted was like particles being pushed out of an energetic core, which is as energetic as the average of audio responses at certain frequencies. In my head, I must have visualized a supernova explosion.&lt;/p&gt;
&lt;p&gt;Since emission is a particle system, there are bunch of parameters which are based on the audio input - particle velocity, spawn rate, color, etc. All of them changing proportionally with the average of audio response over a range of low frequencies. To get a better understanding, these parameters can be played around with in the three.js example of a particle system &lt;a href=&quot;https://threejs.org/examples/webgl_gpu_particle_system.html&quot;&gt;here&lt;/a&gt;. This is the example project which I forked, and tweaked to make those parameters react to the audio response.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Of Web Frontends and Serverless Mock Services]]></title><description><![CDATA[This post is about a hack on ServiceWorkers I did a while ago. Although, not a novel idea anymore, I’m still going to write about it to…]]></description><link>https://ashishdubey.xyz/2017/03/20/roamer.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2017/03/20/roamer.html</guid><pubDate>Mon, 20 Mar 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;em&gt;This post is about a hack on ServiceWorkers I did a while ago. Although, not a novel idea anymore, I’m still going to write about it to continue the legacy of this space, and to celebrate the first commit to the project after Nov 2015.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;What is this?&lt;/h2&gt;
&lt;p&gt;We’re going to talk about &lt;a href=&quot;https://github.com/dash1291/roamer&quot;&gt;Roamer&lt;/a&gt;. Its a small library that utilizes the capability of &lt;a href=&quot;https://developers.google.com/web/fundamentals/getting-started/primers/service-workers&quot;&gt;ServiceWorkers&lt;/a&gt; to act like an intercepting proxy server, and turns it into a web server that serves inside your browser. When you achieve that, there are ton of things you can do. Mocking a web service is one of them, and thats the idea on which Roamer was born.&lt;/p&gt;
&lt;h2&gt;How it works?&lt;/h2&gt;
&lt;p&gt;Roamer is a tiny JS script that can be dropped in your web app which needs to use mocked web services. Using a simple API, you can bind URL endpoints with the mock data that you want in the response for those endpoints.&lt;/p&gt;
&lt;p&gt;Take a look at the following snippet -&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
Roamer.init(function(err) {
  if (err) {
    console.log(&apos;Could not initialize roamer.&apos;);
    return;
  }

  Roamer.bind({
    &apos;/url1/&apos;: &apos;this is hope page&apos;,
    &apos;/url2/&apos;: {
      foo: &apos;bar&apos;,
      syn: &quot;ack&quot;
    }
  });
});
&lt;/pre&gt;
&lt;p&gt;With something as simple as that, you can feed all the AJAX calls in your application with the mock data that they need for testing or prototyping purposes. You don’t need to write a separate server side application and have it running to achieve this.&lt;/p&gt;
&lt;h2&gt;Caveats?&lt;/h2&gt;
&lt;p&gt;Yes! This has only been a toy project so far. Mocking capabilities are very limited. All you can do is bind responses (strings or objects) to URL endpoints. After the latest commit, you can bind different responses with same URL for different HTTP methods, but thats all. But consider giving it a shot, because I’d love to hear how it goes. If you think there is some feature that would be useful to you, please &lt;a href=&quot;https://github.com/dash1291/roamer/issues&quot;&gt;open an issue on GitHub&lt;/a&gt;. Much excited volunteers are welcome to open pull requests :)&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Using ServiceWorkers for Offline Reading]]></title><description><![CDATA[While I was playing with ServiceWorkers, I got a lot of ideas on how I could use this powerful feature. But making my blog accessible…]]></description><link>https://ashishdubey.xyz/2015/09/20/serviceworkers.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2015/09/20/serviceworkers.html</guid><pubDate>Sun, 20 Sep 2015 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;em&gt;While I was playing with ServiceWorkers, I got a lot of ideas on how I could use this powerful feature. But making my blog accessible offline seemed to be the easiest and least useless of them.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So ServiceWorkers is this new-ish browser feature, still under rapid development, that allows web developers take control of the networking part of the requests they make. Using this, one can write pieces of JavaScript code that can intercept all the requests that their web application makes and take further control of them. A ServiceWorker can essentially act like a proxy server. You can use them for caching your HTTP requests, provide offline experience, selectively routing HTTP requests, etc.&lt;/p&gt;
&lt;p&gt;While ServiceWorkers allows you to intercept your HTTP requests, it also provides API for caching your requests. So, you can use these APIs, for populating the ServiceWorker cache, with whatever HTTP requests you want. Once your ServiceWorker intercepts an HTTP request, you can query its cache whether it has the response for that particular request. If you find it, you can return the cached response, otherwise you can propagate the request over the actual network. For creating an offline experience, you would do the same in reverse order: &lt;em&gt;intercept a request -&gt; make the request over the network -&gt; if it succeeds then return the response, else return the cached response&lt;/em&gt;. In some network setups, it might take a while before you know the request has failed over the network and you should return the cached response. This might lead to long response times leading to bad user experience. In such cases, you can return a cached response while you send the request over the network and have in place some mechanism to update the content when you get it from the network.&lt;/p&gt;
&lt;p&gt;Since I’m too lazy to do the latter, I decided to go for the simpler approach. This page initializes a ServiceWorker for this website. The ServiceWorker, once active, populates its cache with all the pages on this blog (Yes I’m sorry, it just did it or its doing it). For subsequent visits to the other pages, the ServiceWorker will intercept the HTTP request, try to fetch the content from the server. If it fails to do so, it will return the content stored in its cache as the response. Thats it. If you’ve read this far, and you’re not on a dial-up connection, the ServiceWorker must have done its job, and my offline readable blog is your reward.&lt;/p&gt;
&lt;p&gt;Wait a minute though. This would work only if you’re on Chrome 40 or later. Might also work on Firefox nightly but I didn’t check it. Let me know if it works for you there, or if it doesn’t work if you expected it.&lt;/p&gt;
&lt;p&gt;If you’d like to start playing with ServiceWorkers, this is a nice talk to watch - &lt;a href=&quot;https://www.youtube.com/watch?v=SmZ9XcTpMS4&quot;&gt;https://www.youtube.com/watch?v=SmZ9XcTpMS4&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’d like to know the current status of ServiceWorkers, follow this link - &lt;a href=&quot;https://jakearchibald.github.io/isserviceworkerready/&quot;&gt;https://jakearchibald.github.io/isserviceworkerready/&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[JS, Browsers in Cloud and Parallel Indexing]]></title><description><![CDATA[This post is about a weekend hack I put together involving a tiny JavaScript library that I wrote a while ago (I call it “infantry”) and…]]></description><link>https://ashishdubey.xyz/2014/12/28/browserstack-infantry.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2014/12/28/browserstack-infantry.html</guid><pubDate>Sun, 28 Dec 2014 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;em&gt;This post is about a weekend hack I put together involving a tiny JavaScript library that I wrote a while ago (I call it “infantry”) and using it on BrowserStack for experimentation and fun.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Story of Infantry&lt;/h2&gt;
&lt;p&gt;The idea of Infantry came into existence a while ago, when I was reading about techniques used for parallel processing of large datasets. At the same time, I was intrigued by the idea of having a website and distributing your processing power across your visitors’ machines. The idea seemed pretty cool to me, so I started my research and found &lt;a href=&quot;https://www.igvita.com/2009/03/03/collaborative-map-reduce-in-the-browser/&quot;&gt;this cool blog post&lt;/a&gt; which meant people had already tried this and it might work. I also learnt about project &lt;a href=&quot;http://boinc.berkeley.edu/&quot;&gt;BOINC&lt;/a&gt; which seemed very impressive to me considering how well they used the concept of collaborative computing and achieve some great results out of it. As a matter of fact, I regularly use BOINC to volunteer some of my idle CPU power hoping that it might be helpful in finding extraterrestrial intelligence someday. Hope is a good thing.&lt;/p&gt;
&lt;p&gt;Coming back to Infantry, I really wanted to build a small map-reduce libary in JS that can be used to parallelize simple logic across machines and run inside a web browser. After much procrastination, I decided to start working on it while I was on a 12 hours long flight. I tried to polish the framework further based on Google’s map-reduce paper and ended up with something actually working.&lt;/p&gt;
&lt;p&gt;The code has always been on GitHub and can be found &lt;a href=&quot;https://github.com/dash1291/infantry&quot;&gt;here&lt;/a&gt;. I have tried to write documentation, but don’t expect too much from it, instead just take a look at the example in the repo.&lt;/p&gt;
&lt;h2&gt;About the Hack&lt;/h2&gt;
&lt;p&gt;For running map-reduce jobs with infantry, one needs to start the infantry server, which acts as master, and to start a worker one has to just navigate to the server’s URL inside a browser. Since, BrowserStack allows you start browsers in cloud and test your web pages inside them, it occurred to me to try it as a test bed for Infantry. I wrote a piece of very buggy and fragile code to build an inverted index for a set of HTML pages. After a few minor fixes, I setup the code on my brand new DigitalOcean server, and when I tried to run it, this is the next thing I see:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/71bf391b1de34143859879d0bd208bf7/6b333/infantry_scr.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 18.714768883878243%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAoUlEQVQY02WPzQqEMBCDfaFVURGt3UMF+y948P1fJdvMoizuIaSd0m+S6jgOeO9FKaVbOecyC1jXFcuyYBxHdF2Hvu9FwzCIN02Dtm1vVSEEge37DuvcFxwTrLVydmVmjBHoPM9FCkopaP0W/wPGGCUNwVprTNMkSa40dH6i6rr+0UuckOtdgN55bNuG8zzB+rnU5RIm5p1z1uZS1nwmet4/rOuIAFLFVu8AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Screenshot&quot;
        title=&quot;&quot;
        src=&quot;/static/71bf391b1de34143859879d0bd208bf7/fb8a0/infantry_scr.png&quot;
        srcset=&quot;/static/71bf391b1de34143859879d0bd208bf7/1a291/infantry_scr.png 148w,
/static/71bf391b1de34143859879d0bd208bf7/2bc4a/infantry_scr.png 295w,
/static/71bf391b1de34143859879d0bd208bf7/fb8a0/infantry_scr.png 590w,
/static/71bf391b1de34143859879d0bd208bf7/526de/infantry_scr.png 885w,
/static/71bf391b1de34143859879d0bd208bf7/fa2eb/infantry_scr.png 1180w,
/static/71bf391b1de34143859879d0bd208bf7/08f6a/infantry_scr.png 1770w,
/static/71bf391b1de34143859879d0bd208bf7/6b333/infantry_scr.png 1774w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;Everything worked as expected. Two workers were started on BrowserStack, and infantry was executing the jobs inside both of them, working to count words in a couple of articles from the &lt;a href=&quot;http://aosabook.org/en/index.html&quot;&gt;AOSA book&lt;/a&gt; and build an inverted index.&lt;/p&gt;
&lt;p&gt;The code involved can be found &lt;a href=&quot;https://github.com/dash1291/browserstack-infantry&quot;&gt;here&lt;/a&gt;. If I get a chance, maybe I will try to iron out the example a bit, and post some execution stats in the updates. Suggestions are welcome.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Communication Dashboard in Firefox Marketplace]]></title><description><![CDATA[This is one of the awfully long-time overdue posts I’ve had in my mind, but have not been able to make it on this space. But since its never…]]></description><link>https://ashishdubey.xyz/2014/03/22/mozilla-summer.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2014/03/22/mozilla-summer.html</guid><pubDate>Sat, 22 Mar 2014 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;em&gt;This is one of the awfully long-time overdue posts I’ve had in my mind, but have not been able to make it on this space. But since its never too late, I’m writing about the cool project I was working on while interning at Mozilla during the summer of 2013.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;About Marketplace&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://marketplace.firefox.com&quot;&gt;Firefox Marketplace&lt;/a&gt;, for the uninitiated is the platform where developers can host their Firefox apps which run on desktop and mobile (of course including Firefox OS). It acts as the central repository of apps, from where users can download and install apps on their systems. And by that I don’t mean a plain repository of apps which just allows you to download apps, but also essentials like compatibility checks, app analytics, ratings, reviews, etc. Just like &lt;a href=&quot;https://addons.mozilla.org&quot;&gt;Firefox Add-ons&lt;/a&gt;, there are apps for various kinds of users on Marketplace. Since Mozilla cares much about the quality of the apps served to its users, it makes sure that the apps meet a quality standard before they are available on the Marketplace. For this purpose, there is process of App Review which comes after a new app is submitted to Firefox Marketplace and before it is available to the users for download. App reviewers, which include paid staff and volunteers, take a close look at the submitted apps, beyond just the description of it. It includes inspecting the app’s functionality, performance, and security. If the reviewers like it, it goes live for the users to download, if not, the developer (who submits the app) is notified about the issues found during the review, and the developer is expected to fix those before it can be reviewed again and made public.&lt;/p&gt;
&lt;h2&gt;About the Problem&lt;/h2&gt;
&lt;p&gt;So, in the Marketplace workflow, we have three kinds of users namely, developers, reviewers and users (Firefox users who download the apps). The review process is basically hidden from the users as it is not relevant to them. Its the developers and reviewers which interact with each other during the review process mainly for feedback, reporting issues and asking questions. The Reviewer Tools provides a dashboard for the reviewers to review apps, which allows them to pick apps they want to review, and take actions on the apps they are reviewing (that is reject, make public, delete or ask for more information). On the other hand, Developer Hub is the dashboard for the developers, which they can manage apps (that is upload an app, edit uploaded apps). Though, this is an efficient workflow for both developers and reviewers, but on the communication front they are a bit disconnected. Every time, a reviewer takes an action on an app, its developer is notified about the action and the enclosed comments in an email. If the developer has any question or comment on the action, they reply back to the email which is delivered to a mailing list which has all the reviewers as its members. While the process works and is transparent, its not the best experience for both developers and especially reviewers. There is no central place in Marketplace where users can view all their conversation. It is totally tied up with their email. Also, communication on mailing lists gets messy after a while, reviewers have to keep track of developers’ email addresses, among other hassles. So my project for the summer was to revamp this process in the following ways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a dashboard for both reviewers and developers to access their present and past conversations. This should be used to read and reply to the messages exchanged between the users.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bridge the email conversation and dashboard, so that the users can use both modes of communication as they please.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;About the Solution&lt;/h2&gt;
&lt;p&gt;This is what a part of solution looked like:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/56b71cb147afc4990eb059c0ecaa27a2/cac6d/commbadgescreen.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 51.54998258446535%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABYklEQVQoz32Sy07DMBBF8/9/UjZsu2CB2HQBVIIKiVYVUIUmaRwntvOw86CXsduUpBQsXdnOeI7vTOwJISBVDh74+FjM8RmECLZbZFkGG/tPUkqkaTo66zHGwJIEcRQi9DcIowgBQXcsAU8zcIolZ+Kc08xhc+M4dnMvz97ipJRzarTG1WSC29kDIi7QNg3OR1mWyPMcSh1yVc8geZfKeFr7eA8YiqpG03Touv1Idd2iqgwBlTs/zD85FEIegQrPmwThNoKhJK07AuxPMuYLbQtqRwLff6UeJi6nNzMAHh3SrfN1gLfVElnMHNBCbOU91K7LUlMv2Qn0C+g+HgOmaiFFQWtFZdEL4Bn9SUHrwu3z3PawcM6GsIsO7eHp3TXul8+QhSZ3mvpVORljnIrCQsewP0u2N08fbzBbLSAyiUtD00s4OBy7OwP+BF98hXQXI085uanJXTNQ6/pa0Qs4h1l9A4qT+Z5QLF7XAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Dashboard Screenshot&quot;
        title=&quot;&quot;
        src=&quot;/static/56b71cb147afc4990eb059c0ecaa27a2/fb8a0/commbadgescreen.png&quot;
        srcset=&quot;/static/56b71cb147afc4990eb059c0ecaa27a2/1a291/commbadgescreen.png 148w,
/static/56b71cb147afc4990eb059c0ecaa27a2/2bc4a/commbadgescreen.png 295w,
/static/56b71cb147afc4990eb059c0ecaa27a2/fb8a0/commbadgescreen.png 590w,
/static/56b71cb147afc4990eb059c0ecaa27a2/526de/commbadgescreen.png 885w,
/static/56b71cb147afc4990eb059c0ecaa27a2/fa2eb/commbadgescreen.png 1180w,
/static/56b71cb147afc4990eb059c0ecaa27a2/08f6a/commbadgescreen.png 1770w,
/static/56b71cb147afc4990eb059c0ecaa27a2/cac6d/commbadgescreen.png 2871w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;This is the communication dashboard frontend which is written over the same codebase that the Firefox Marketplace is based on, that is &lt;a href=&quot;https://github.com/mozilla/fireplace&quot;&gt;fireplace&lt;/a&gt;, which is essentially a homegrown client-side framework with Marketplace specific bits like how the requests are dispatched, responses are cached, and rendered. Later, most of the Marketplacey commonware was abstracted out and &lt;a href=&quot;https://github.com/mozilla/commonplace&quot;&gt;commonplace&lt;/a&gt; was born, which served as the base for all other Marketplace related projects, including communication dashboard frontend, source code of which resides in &lt;a href=&quot;https://github.com/mozilla/commbadge&quot;&gt;commbadge&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;More About the Solution&lt;/h2&gt;
&lt;p&gt;A little about the frontend was described above, but that was only a part of the entire thing. The frontend is basically a client-side app which talks to the Marketplace REST API, for reading/writing communication dashboard data. This is actually how Firefox Marketplace works. The frontend is a client-side app which fetches data from the Marketplace API and renders it using &lt;a href=&quot;http://jlongster.github.io/nunjucks&quot;&gt;Nunjucks&lt;/a&gt; templating library. The Marketplace API codebase is written in Python/Django (codename &lt;a href=&quot;https://github.com/mozilla/zamboni&quot;&gt;zamboni&lt;/a&gt;), and is huge and might require an additional blog post to get into the details. For the purpose of this post, lets just stick to the details of Marketplace API relevant to the communication dashboard API.&lt;/p&gt;
&lt;p&gt;The REST API is written using the &lt;a href=&quot;http://django-rest-framework.org&quot;&gt;Django REST Framework&lt;/a&gt;, which makes it really easy and quick for writing new API endpoints, once you understand how it works. Since, I had worked on Tastypie before, it took me a while to understand different parts of DRF work together, but spending time reading the documentation and codebase itself, yielded good results. I realized that DRF is infact, very simple and flexible framework, making it really easy to control different parts of an API request lifecycle in DRF, simply by extending different classes that DRF provides. I’ve actually used DRF for another personal project of mine, and it helped setup an API in no time.&lt;/p&gt;
&lt;p&gt;One requirement of the project, is to be able to handle the incoming email replies. This means that, a reply to a message sent from communication dashboard can be sent over email and the replies should be tied to the same conversation thread. This is done by sending an email for every message that is sent from the communication dashboard, to the recipients of the message through email. A unique reply token is embedded in the &lt;em&gt;Reply-To&lt;/em&gt; address of each email, which internally corresponds to a single conversation thread. Whenever a reply is sent to the reply address, the email server pipes the email to the communication dashboard API, which in background then extracts this reply token and figures out which thread it belongs to and creates its record in the database. Works pretty neatly.&lt;/p&gt;
&lt;h2&gt;About the Result&lt;/h2&gt;
&lt;p&gt;Much of the prototyping was done by the time I was done with my internship, but the project could not get deployed, which kept me from addressing the real issues it might face in production. But it was a fun ride. It was challenging to find edge cases, and dozen of issues which would arise in every single bug that was part of the project.&lt;/p&gt;
&lt;p&gt;My project presentation can be viewed at &lt;a href=&quot;https://air.mozilla.org/2013-intern-dubey&quot;&gt;air.mozilla.org/2013-intern-dubey&lt;/a&gt;, slides of which are available &lt;a href=&quot;http://slid.es/ashishdubey/internpresentation13&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In a nutshell, I had an awesome summer!&lt;/p&gt;
&lt;h2&gt;Thanks&lt;/h2&gt;
&lt;p&gt;The awesome summer would not be possible and much fun without my supervisor &lt;a href=&quot;https://twitter.com/cvanw&quot;&gt;cvan&lt;/a&gt;. Learnt so much from him and &lt;a href=&quot;https://twitter.com/mattbasta&quot;&gt;Matt Basta&lt;/a&gt; while working on commbadge, commonplace and zamboni, having fun code reviews. &lt;a href=&quot;https://twitter.com/clouserw&quot;&gt;Wil Clouser&lt;/a&gt; and the entire Marketplace team for a place in the awesome team.&lt;/p&gt;
&lt;p&gt;Special thanks to &lt;a href=&quot;http://ngokevin.com&quot;&gt;Kevin Ngo&lt;/a&gt; for taking forward the work on communication dashboard, making it awesome and suck less.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Putting Some Crunch in the Network]]></title><description><![CDATA[Most of us, who write web pages, sometimes want to serve their content from the local server. Now if I’m one of the students of a college…]]></description><link>https://ashishdubey.xyz/2012/11/9/crunch-in-network.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2012/11/9/crunch-in-network.html</guid><pubDate>Fri, 09 Nov 2012 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Most of us, who write web pages, sometimes want to serve their content from the local server. Now if I’m one of the students of a college, where there are no ports forwarded on which I’m allowed to serve my content, being on the college’s network. Thats bad because I often want to be able to serve some static pages or files from my local system to the internet. I wish there was no firewall but there are somethings you cannot change and have to live with. But certainly, one can adapt. I’ve made a small attempt towards such an adaptation.&lt;/p&gt;
&lt;h2&gt;What about adaptation?&lt;/h2&gt;
&lt;p&gt;I started writing some experimental tools which would allow me to serve content from any such network where I cannot serve directly to the internet. All I require is just one port that allows me to make outbound remote connections from my network and a remote server, which should be under my control. I need to run a python program on my local system and another on my remote server and I get a bypassing highway for my content(which is on my local system) to reach where it is needed. Its really that simple, but works, hence very useful.&lt;/p&gt;
&lt;h2&gt;Enter Crunch&lt;/h2&gt;
&lt;p&gt;So the tools consist of a server and client, which runs a serving node on your local machine. Lets call these serving nodes as crunch nodes. The server receives HTTP requests from the internet, and according to URI of the request, pulls content from a crunch node. Now an important thing to note here is that the crunch nodes create persistent connections with the server. They initialize these connections with the server, so the need to accept connections on crunch nodes is eliminated.&lt;/p&gt;
&lt;p&gt;The server and the crunch nodes communicate over a very basic TCP protocol(something like IRC). Since, it has just begun yet, there are limits to serving. It can only serve static files. Some HTML, CSS, JS, or any other file. Moreover, its also not fit for serving large files yet. I’ve seen it break while serving JPEGs of sizes like 200KBs. Its an issue, but not a big one, so it will be fixed soon. Apart from that, I’ve planned so many enhancements to it. Perhaps, too many to list here. To put it simply and in short, I would love to make it fit for serving any pretty thing someone would want to serve from a local system, even dynamic web content. But, thats long way ahead.&lt;/p&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;It does not make sense for such a thing to exist if you can’t use it right? So lets squeeze out a simple feature of serving a small text file with crunch.&lt;/p&gt;
&lt;p&gt;Install crunch:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
$ pip install -e git+https://github.com/dash1291/crunch.git#egg=crunch
&lt;/pre&gt;
&lt;p&gt;Write your server:&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
from crunch.server import runserver

runserver(8000, 8001)
&lt;/pre&gt;
&lt;p&gt;When you run the above code, your server will start accepting HTTP requests on port 8000 and will accept connections from crunch nodes on port 8001. You have the liberty to choose those ports. As a general rule, the first port(HTTP) can be anything because on your remote server, you can accept connections on most of the ports. But the second port can only be a port which is open on your network, such that it allows outbound remote connections. For example, in my own setup, I use port 80 as the HTTP port, and 21 as the crunch port, because 21 is one of the few ports that I can use to make outbound remote connections. This could work for you or you might need to alter it a bit to make it work for you.&lt;/p&gt;
&lt;p&gt;We will need to create database schema for the users and atleast one user account to be able to connect to the server. So we’ll do that from the Python shell.&lt;/p&gt;
&lt;pre class=&quot;pycon&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; from crunch.crunchauth import add_account, create_schema
&amp;gt;&amp;gt;&amp;gt; create_schema()
&amp;gt;&amp;gt;&amp;gt; add_account(&apos;someone&apos;, &apos;someonespassword&apos;)
&lt;/pre&gt;
&lt;p&gt;Write your crunch client:&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
from crunch.crunchclient import start_client

config = {
	&apos;username&apos;: &apos;someone&apos;,
	&apos;password&apos;: &apos;someonespassword&apos;
	&apos;address&apos;: &apos;something.com&apos;,
	&apos;port&apos;: 8001
}

start_client(config)
&lt;/pre&gt;
&lt;p&gt;When you run this code, you will be connected to the crunch server. Remember to put in the right values to the config fields. When its running, whenever, the server receives an HTTP request at &lt;em&gt;/someone/hello.txt&lt;/em&gt;, the crunch client will look for the file &lt;em&gt;hello.txt&lt;/em&gt; in the current directory and if found, it will send it to the server which is written back as a response to the HTTP request.&lt;/p&gt;
&lt;p&gt;Lets put it to test, assuming there is a &lt;em&gt;hello.txt&lt;/em&gt; in the current directory which contains &lt;em&gt;Hello World&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
$ curl http://something.com:8000/someone/hello.txt
Hello World
&lt;/pre&gt;
&lt;p&gt;So thats it. One last point to note here is, the project is open for hacking. If you are over just suggestions, you are welcome to pitch in some code and make it better yourself. The code can be found on &lt;a href=&quot;https://github.com/dash1291/crunch&quot;&gt;GitHub&lt;/a&gt;. Use it or fork it, if you want to make it better, and put some crunch in your network.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Collaborative VisualEditor: First Demo]]></title><description><![CDATA[I feel pretty bad for not having written about my Google Summer of Code project that I’m undertaking this summer for Wikimedia Foundation…]]></description><link>https://ashishdubey.xyz/2012/7/5/realtimeve-first-demo.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2012/7/5/realtimeve-first-demo.html</guid><pubDate>Thu, 05 Jul 2012 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I feel pretty bad for not having written about my Google Summer of Code project that I’m undertaking this summer for Wikimedia Foundation for prototyping collaborative editing feature for the new under-development VisualEditor(wysiwyg). Its been a while since I was selected, and started working on it, so I won’t go into discussing the story around how I got started on it. But, I would like to discuss about the present state of the project, where its heading and also a bare working demo of the code produced so far.&lt;/p&gt;
&lt;p&gt;So the VisualEditor project is a wysiwyg editor for MediaWiki, designed from scratch keeping in mind the complexities of the Wikitext mapping to HTML and data structures suitable for inline editing. The changes to the text in VisualEditor are in the form of transactions. There are transactions for insertion/deletion of text as well as applying formatting attributes to a portion of text.
So most of the collaboration thing revolves around these transactions. There is a collaboration server which listens for new connections from clients who requests to initiate an editing session. A client module establishes connection with the server, and listens to the changes made in the document and translates the resulting transactions to the server. A thing that should be noted here is, the project is under Phase 1 which would support only one client who publishes changes to the server’s document and other connected clients simply listen to these changes and apply them in their local documents. Phase 2 would support multiple publishers which would bring in conflicts and concurrency issues and perhaps measures to fight with them.&lt;/p&gt;
&lt;p&gt;So, there is a small list of things which have been done so far -&lt;/p&gt;
&lt;h2&gt;On the Server&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Listen to new connections and define I/O events.&lt;/li&gt;
&lt;li&gt;Bind the VE modules into a single module which is imported as a top-level &lt;code class=&quot;language-text&quot;&gt;ve&lt;/code&gt; object.&lt;/li&gt;
&lt;li&gt;Create a new user session on every new connection and associate with the requested document.&lt;/li&gt;
&lt;li&gt;Create a new document model instance if an editing session is initiated on a new document.&lt;/li&gt;
&lt;li&gt;Apply incoming transactions to the document model.&lt;/li&gt;
&lt;li&gt;Invoke/revoke publishing rights on user sessions.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;On the Client&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Initialize a new session with the server on manual request.&lt;/li&gt;
&lt;li&gt;Enable/Disable editing based on publishing right flag received from the server.&lt;/li&gt;
&lt;li&gt;Listen to document change events and push transactions to the server if publishing is given.&lt;/li&gt;
&lt;li&gt;Apply incoming transaction from the server if the origin of the transaction is a different client.&lt;/li&gt;
&lt;li&gt;Retain the document state before collaborative editing is turned on so it can be restored when collaborative mode is turned off.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Brief Internals&lt;/h2&gt;
&lt;p&gt;The collaboration server is a Node.js based server, which uses socket.io for making persistent connections with the clients for realtime communication. The client module binds against the server’s API which is laid in terms of the socket.io events defined in the server. All the VE functionality is accessed through a binding module which exports a top-level &lt;code class=&quot;language-text&quot;&gt;ve&lt;/code&gt; object much like the &lt;code class=&quot;language-text&quot;&gt;ve&lt;/code&gt; namespace is used on the client-side. The server can parse the wiki pages internally using the parser modules and also can fetch the parsed HTML output from an external parsoid service over HTTP. As of now, an external parsoid service is used for scalability until something better can be figured out.&lt;/p&gt;
&lt;h2&gt;What Should be Coming?&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Authentication&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Some code has been written for handling user authentication on the socket connections level but is not functional right now. Also, due some review on the proper technique to do it, its deferred for a little later.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Editing control transfer&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Right now editing control is given to any user who joins when there is no client with publishing right is connected to the server on a same document. A publishing user before disconnecting might want to transfer the editing control to a client which is already connected as non-publishing client.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Transactions buffering&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Right now every transaction is fired towards the server as it is generated in the VisualEditor. This would be quite a network activity. So, there would be some buffering and capping of the transactions before they are transported to the server.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;About the Demo&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Updated fork of &lt;code class=&quot;language-text&quot;&gt;realtimeve&lt;/code&gt; branch of VisualEditor.&lt;/li&gt;
&lt;li&gt;Runs the collaboration server alongside the parsoid service in the same master process but on a different port. The collaboration server uses this parsoid service to fetch parsed HTML over HTTP.&lt;/li&gt;
&lt;li&gt;The client UI lets users to turn-on/off the collaborative editing mode.&lt;/li&gt;
&lt;li&gt;The user with the editing control is shown in green in the users list displayed on the right.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&quot;http://ashishdubey.info/mw/index.php&quot;&gt;&lt;strong&gt;Link to the demo site&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Less Important (Fancy) Information&lt;/h3&gt;
&lt;p&gt;The demo is hosted on an Amazon EC2 micro instance, running Ubuntu 11.10. The server uses Node.js v0.8.1 and socket.io v0.9.6. The cluster module used in running the parsoid service forks five workers while running the collaboration server on the master process.&lt;/p&gt;
&lt;h2&gt;Reporting issues&lt;/h2&gt;
&lt;p&gt;If you’ve got suggestion to improve a feature, or about a new feature or you want to report some bugs, you can get in touch with me directly through my email - ashish[dot]dubey91[at]gmail[dot]com.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Open source Wowness]]></title><description><![CDATA[This is the first in set of the delayed blog posts that I wanted to write since long but somehow did not. After the awesome December…]]></description><link>https://ashishdubey.xyz/2012/4/17/opensource-wowness.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2012/4/17/opensource-wowness.html</guid><pubDate>Tue, 17 Apr 2012 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This is the first in set of the delayed blog posts that I wanted to write since long but somehow did not. After the awesome December dedicated to Python and Mozilla, and with Mozilla’s AMO project being the first open source project that I contributed to, I easily understood the joy and learning that comes through contributing to an awesome open source project. And with that motivation, and mostly with a desire of contributing to another open source project I turned to &lt;a href=&quot;http://mediawiki.org&quot;&gt;MediaWiki&lt;/a&gt;. I was definitely not here for PHP parts of it but still to get a hang of the software I developed a small experimental extension for it. It was a smooth run, so I continued to discover more until I discovered the project that I was maybe looking for, that is, the &lt;a href=&quot;http://mediawiki.org/wiki/Visual_editor&quot;&gt;Visual Editor project&lt;/a&gt;. This looked to be a really cool project at first, because I’ve had some tough time editing wiki pages for the first time using the wiki markup text. But the Visual Editor project simply appeared to solve the wiki editing problems for ever and everyone, and so was it. Mostly with the desire to make some good amount of contribution to MediaWiki through GSoC, I started hacking on the Visual Editor project with an aim of prototyping the collaborative editing feature on Visual Editor. With hacking came the learning, mainly on numerous pro JS practices, so I was enjoying it! I talked to alot of devs mainly those onboard the VE team. They told me what made sense and what not in what I was aiming.&lt;/p&gt;
&lt;p&gt;By this time, I really wished to be the part of this community. I attended a hackathon in Pune in February which happened to be a great event where I worked on Wikipedia’s official mobile app and met some awesome people from Wikimedia Foundation. And this is when I realized how awesome the Wiki community is and felt the desire to make some considerable contribution to it.&lt;/p&gt;
&lt;p&gt;A unique thing about contributing to Wikimedia projects is, your work reaches people who use so many different languages which is achieved better in no other open source project. And that is the joy a developer seeks while contributing to any open source project.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[December of Things]]></title><description><![CDATA[I’m just done with a month long winter break after the semester finished at
school. The month of December was about some travel, lot of…]]></description><link>https://ashishdubey.xyz/2012/1/5/december-of-things.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2012/1/5/december-of-things.html</guid><pubDate>Thu, 05 Jan 2012 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I’m just done with a month long winter break after the semester finished at
school. The month of December was about some travel, lot of sleep, occasional
movie sprints, and lastly but most importantly it was about taking my
experiences with Python some steps forward.The list of experiments included a
handful with Twisted including an incomplete(+ abandoned) networking project,
gitpython, a small screen grabber(+ uploader) script and a couple of patches
contributed to one of the Mozilla.org websites that is
&lt;a href=&quot;http://addons.mozilla.org&quot;&gt;addons.mozilla.org&lt;/a&gt; a.k.a. AMO. These experiments
though not involving coding a huge project all the way, did well in teaching
me some really important things both at fundamental levels and sometimes
arbitrary magic tricks.&lt;/p&gt;
&lt;h2&gt;Recap. Me Earlier with Python.&lt;/h2&gt;
&lt;p&gt;I started learning Python about 4 months back in September, last year. And it
was this time, that I realized that Python while being easy and quick to learn
can be very useful. I did my first Python work towards a special task which
was creating a script that runs as a daemon on my shared web host, crawls for
artists on Last.fm, pull their biographical information and look for the
location terms using Yahoo Placemaker API and eventually determine the
geographical location to which the artist belonged. I needed such a bot script
to populate a database of artists with their geographical locations for my
website project which was about music discovery over geographical data. My
shared host supported Python, I heard Python would be good for making such
scripts, and I wanted to learn Python so it was an obvious to choose Python
for the script. Being a PHP programmer, I used analogies to PHP methods of
parsing the web documents, and random smaller stuff to make a quick leap to
learning Python while directly coding my script. It was a smooth run, much
much smoother than I had expected and apart from some nasty bugs which broke
the script sometimes, it worked really good. Good enough to give me enough
artists to get the website live within 3 days after starting the script on my
shared web host. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Enclosed Lessons&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Python has everything that PHP has. urllib, xml_minidom made me feel home.&lt;/li&gt;
&lt;li&gt;Life’s easier without braces.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Some Links&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Checkout the website. &lt;a href=&quot;http://geonres.com&quot;&gt;Geonres.com&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Checkout the source of the script on &lt;a href=&quot;https://github.com/dash1291/geonres_bot&quot;&gt;GitHub&lt;/a&gt;. &lt;/li&gt;
&lt;li&gt;Checkout the website source on &lt;a href=&quot;https://github.com/dash1291/geonres.com&quot;&gt;GitHub&lt;/a&gt;. &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Exposure to the Community. PyCon India 2011&lt;/h2&gt;
&lt;p&gt;I registered for PyCon India before actually starting to work with Python
which was because of my desire to learn the awesome language. I was really
excited as it was the first time that I was going to attend such a large
community meetup. Being interested in web development, I attended every
talk/session that gave me a hint of something that I could use to build web
applications using Python notably including some like the low level web-
scrapping tutorial, a talk on Redis, and another one on pyjamas. They came
with great learning and I got to know people who’ve been doing great things
with the awesome language that I was so wanted to learn. All that was a great
motivation package to keep up and working. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Enclosed Lessons&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;One can do pretty much anything, perhaps more things than any other language using Python, in ways that are easier and quicker.&lt;/li&gt;
&lt;li&gt;Python has an awesome community full of cool people who do cool stuff every day, every night and in every part of the globe.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Trying out things with Web Development with Python. Learning Django.&lt;/h2&gt;
&lt;p&gt;When I started learning Python, I knew I wanted to use it as one my tools for
developing web applications along with PHP. I heard the names of some web
frameworks built in Python like Django, Google’s webapp, pylons, and web2py.
When I visited PyCon India, I heard more about them and much more about Django
and how much better it is than any of the Python web frameworks out there, or
perhaps better than many web frameworks built in different languages too. I
wanted to give it a wild try to learning it. I usually have a tendency to
learn while doing, but I didn’t have an idea of an application to start with
so I though I would remake a web application that I earlier developed using
PHP(I called it shitstream), but this time in Django. Since, it was my first
attempt to any MVC framework, shitstream appeared to be a good choice to get
some basic concepts built up, as the app was simple and compact. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Enclosed Lessons&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Django is the best thing one can use to build web applications.&lt;/li&gt;
&lt;li&gt;Unless I’m out of choices or luck, I would never go back to PHP again.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Checkout the source of Shitstream app on
&lt;a href=&quot;https://github.com/dash1291/shitstream&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Helping make Web Better. Fixing @ &lt;a href=&quot;http://addons.mozilla.org&quot;&gt;addons.mozilla.org&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I wanted to contribute to Mozilla in any way possible since the day I got to
know about Open Source Software, about Mozilla, and how Mozilla keeps doing
awesome things which make the web much more awesome than it was, or perhaps
much more awesome than how it is now. But, with a huge rack of Mozilla
projects to choose from, my unawareness about them, and my lack of focus in a
single field kept me confused whenever I wanted to give a try to contributing
to one of the projects at Mozilla. But when I learnt Django, and accidentally
browsing through the Web Dev projects at Mozilla’s Contribution page, I found
my thing. Having developed two Firefox addons earlier, I was aware of AMO, or
I should say that I hung-out quite alot on that website. And, AMO being the
first in the web dev projects list, I could not wait to browse through the
bugs list and kick out a few of those annoying bugs. It did not take me long
to fork the Mozilla’s github repository of Zamboni, clone it to my local box,
and start trying to set it up. But setting up the whole thing, that is my
local AMO instance took me 3 days. Yes, 3 days! It was actually a pain setting
up the huge stack on my Ubuntu system. Thanks to folks on IRC, who are patient
great helpers and played angels in helping me setting it up especially Jeff
Balogh. Not only setup, but he also guided me to how to start fixing my first
bug and led me all the way to my first pull request, which was much required
for me as it was not only my first attempt to fix a bug on this project, but
also my first attempt to fix anything on any open source project. My first
pull request although took a while to be closed with a merge of my proposed
patch because it was awaiting review from the reporter and in the meantime I
was also busy with college. But as the winter break started, I got it merged,
and also worked to fix a couple more bugs and got my patches merged. All the
while I was working on these bugs, Mozilla developers hanging out on IRC were
really helpful while being prompt at suggestive code reviews especially Chris
Van, who is also the commiter of all my patches to the original AMO git
repository. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Enclosed Lessons&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Most importantly, I learnt how to write code that is readable and stylish. Thanks to Mozilla’s adoption of PEP8.&lt;/li&gt;
&lt;li&gt;Ample of git stuff, I knew a very limited subset of git before starting to work on this project. I’m still terrible, but much better than what I was earlier.&lt;/li&gt;
&lt;li&gt;git rebase can be dangerous while working with a lot of people.&lt;/li&gt;
&lt;li&gt;find . -name “*.pyc” -delete is simple but can be magical sometimes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Have a look at my commits merged with AMO
&lt;a href=&quot;https://github.com/mozilla/zamboni/commits/master?author=dash1291&quot;&gt;here&lt;/a&gt;. So
that was pretty much my Python story so far, and another of my favorite
December. What I’ve figured out so far is that Python and Mozilla communities
are two of the best Open Source Communities working to promote openness
everywhere and Mozilla doing their every bit to build an open web platform
which is not just about Mozilla Firefox but freedom and choice to the users of
web around the globe.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Setting up Apache Server for Django with mod_wsgi]]></title><description><![CDATA[Django is a very cool web development framework which comes with its own
lightweight development server which is best for testing the…]]></description><link>https://ashishdubey.xyz/2011/10/29/django-apache-modwsgi.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2011/10/29/django-apache-modwsgi.html</guid><pubDate>Sat, 29 Oct 2011 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Django is a very cool web development framework which comes with its own
lightweight development server which is best for testing the application. But
when it comes to deploying the application for the outer world, more efficient
and secure web server like Apache is preferred. Now, web developers who have
been developing applications using PHP might find it very easy to deploy their
applications on Apache(as they have easy configurable PHP module, or they
could just find a LAMP stack for if they were on Linux, so they would get
everything cooked. But when it comes to combining python web frameworks like
Django with Apache, things turn out to be less obvious. My experience weren’t
smooth at all while trying to get my Django project work on Apache. And since
I was trying to configure it with already installed LAMP stack on my Ubuntu
system, things went really bad. Since, there are so many things integrated in
a compilation like LAMP stack, there are as many things which can go wrong
while configuring Django on an Apache server. So, its recommended that a clean
and separate Apache installation should be used so that things are easier to
diagnose one by one.&lt;/p&gt;
&lt;h2&gt;Step 1 - Install Apache HTTP Server&lt;/h2&gt;
&lt;p&gt;You should install a clean build of Apache in case you haven’t already. Its
easy, just follow the docs given here &lt;a href=&quot;http://httpd.apache.org/docs/2.2/install.html&quot;&gt;http://httpd.apache.org/docs/2.2/instal
l.html&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Step 2 - Install mod_wsgi&lt;/h2&gt;
&lt;p&gt;Now that you’re done with Apache, you need to install mod_wsgi which is a WSGI
module for Apache. Know more about it here.
&lt;a href=&quot;http://code.google.com/p/modwsgi/&quot;&gt;http://code.google.com/p/modwsgi/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Installation instructions &lt;a href=&quot;http://code.google.com/p/modwsgi/wiki/InstallationOnLinux&quot;&gt;http://code.google.com/p/modwsgi/wiki/InstallationO
nLinux&lt;/a&gt; &lt;/p&gt;
&lt;h2&gt;Step 3 - Load and Configure mod_wsgi in Apache config&lt;/h2&gt;
&lt;p&gt;This is where you edit the Apache
configuration file and tell Apache to load mod_wsgi module using the DSO
method. You need to edit /conf/httpd.conf file and add the following directive
to it&lt;/p&gt;
&lt;pre class=&quot;apache&quot;&gt;
LoadModule wsgi_module /usr/lib/apache2/modules/mod_wsgi.so
&lt;/pre&gt;
&lt;p&gt;Also, at the end of the httpd.conf file, add the following directives&lt;/p&gt;
&lt;pre class=&quot;apache&quot;&gt;
WSGIScriptAlias / &amp;lt;path-to-your-django-project&amp;gt;/test.wsgi
&amp;lt;Directory path-to-your-django-project&amp;gt;
Order deny,allow
Allow from all
&amp;lt;/Directory&amp;gt;
&lt;/pre&gt;
&lt;p&gt;The first line in the above directives loads mod_wsgi module into the Apache
instance. The second directive &lt;Directory&gt; directive is there to make sure
Apache can access the directory given in the path. Also, make sure you replace
&lt;path-to-your-django-project&gt; with its appropriate value.&lt;/p&gt;
&lt;h2&gt;Step 4 - Test WSGI&lt;/h2&gt;
&lt;p&gt;Now that we’ve configured Apache to load the mod_wsgi module, its time to test
if it works. To do that, create a file &lt;path-to-your-django-project&gt;/test.wsgi
with the following content.&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
def application(environ, start_response):
	status = &apos;200 OK&apos;
	output = &apos;Hello World!&apos;
	response_headers = [(&apos;Content-type&apos;, &apos;text/plain&apos;),
	(&apos;Content-Length&apos;, str(len(output)))]
	start_response(status, response_headers)
	return [output]
&lt;/pre&gt;
&lt;p&gt;Now test if it works by trying &lt;a href=&quot;http://localhost&quot;&gt;http://localhost&lt;/a&gt; in your browser, you should
get Hello World for obvious reasons.(and yes make sure Apache is running)&lt;/p&gt;
&lt;h2&gt;Step 5 - Test the bad WSGI&lt;/h2&gt;
&lt;p&gt;Now, that the simple WSGI application runs, we need to test something which
generally has issues which need to be resolved before moving on to using
Django as a WSGI application.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;The Expat woe&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;When we move to more complicated WSGI applications, and as the applications
start using libraries whose versions conflict with the versions used by
Apache, there are issues like Apache crashing and incorrect response. One such
library is libexpat. Know more about it here &lt;a href=&quot;http://expat.sourceforge.net/&quot;&gt;http://expat.sourceforge.net/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It happens in many situations that the expat module used by python(that is the
default one on a system) has a different version than that used by Apache(it
has its own). In such a situation, there is Segmentation Fault encountered by
Apache and it crashes. To test it if you encounter that issue, just make the
following entry in your test.wsgi file.&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
import pyexpat
&lt;/pre&gt;
&lt;p&gt;Now, again try &lt;a href=&quot;http://localhost&quot;&gt;http://localhost&lt;/a&gt;. If you get proper response as earlier then
you are free from the expat issue while if you get ‘no response’ error then
you need to resolve the expat issue before turning on to Django.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Resolving Expat Issue&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;There is this great post on handling expat issue. &lt;a href=&quot;http://code.google.com/p/modwsgi/wiki/Issues%0AWithExpatLibrary&quot;&gt;http://code.google.com/p/mod
wsgi/wiki/IssuesWithExpatLibrary&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since, python’s expat module is hard to replace, its
recommended you change Apache’s expat module. Either update it or simply
replace it with your system’s expat. I consider replacing it. After all done,
restart Apache and test &lt;a href=&quot;http://localhost&quot;&gt;http://localhost&lt;/a&gt;, if all went good it should be
working fine.&lt;/p&gt;
&lt;h2&gt;Step 6 - Configure WSGI for Django&lt;/h2&gt;
&lt;p&gt;If you’ve successfully dealt with running WSGI with expat loaded, you should
then be able to run Django after a little bit of work if not-so-common issues
don’t fall in your way. For connecting to Django with mod_wsgi, you should
create a new django.wsgi in the same directory as test.wsgi and set
WSGIScriptAlias to that very file. Enter the following code to django.wsgi and
you’re on the go.&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
import os
import sys
root = os.path.join(os.path.dirname(__file__),&apos;..&apos;)

sys.path.insert(0,root)
os.environ[&apos;DJANGO_SETTINGS_MODULE&apos;]=&apos;&amp;lt;your-project&amp;gt;.settings&apos;

import django.core.handlers.wsgi
application = django.core.handlers.wsgi.WSGIHandler()
&lt;/pre&gt;
&lt;p&gt;Replace &lt;code class=&quot;language-text&quot;&gt;&amp;lt;your-project&amp;gt;&lt;/code&gt; with your project’s name. &lt;/p&gt;
&lt;h2&gt;Step 7 - Test Django&lt;/h2&gt;
&lt;p&gt;So you’ve worked out all the way to the point where you would need to test if all
your setup works fine. Its recommended that you use a clean Django application
so that you don’t encounter issues related to database and other stuff.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Customized authentication for WordPress users]]></title><description><![CDATA[I wanted to integrate Facebook’s authentication with my WordPress site’s user login system. This had led me stuck for a couple of days…]]></description><link>https://ashishdubey.xyz/2011/06/17/custom-auth-wordpress.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2011/06/17/custom-auth-wordpress.html</guid><pubDate>Fri, 17 Jun 2011 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I wanted to integrate Facebook’s authentication with my WordPress site’s user login system. This had led me stuck for a couple of days because of all the authentication routes that I’ve known in WordPress would require a correct password to complete authentication. But, in my case, I just needed to authenticate a user without actually user providing a password. That means, I needed a method by which I could authenticate users using just their username or user ID. So after a lot of hacking and reading, I finally found this method that works out for me.
It basically deals with using filters, precisely &lt;code class=&quot;language-text&quot;&gt;authenticate&lt;/code&gt; filter. The functions added to this filter are executed in &lt;code class=&quot;language-text&quot;&gt;wp_authenticate&lt;/code&gt; function which is defined in &lt;code class=&quot;language-text&quot;&gt;pluggable.php&lt;/code&gt; and is the authentication end point in WordPress. If you watch the code in &lt;code class=&quot;language-text&quot;&gt;user.php&lt;/code&gt;, there you would find that two functions added to this &lt;code class=&quot;language-text&quot;&gt;authenticate&lt;/code&gt; filter, which are &lt;code class=&quot;language-text&quot;&gt;wp_authenticate_username_password&lt;/code&gt; with priority 20 and &lt;code class=&quot;language-text&quot;&gt;wp_authenticate_cookie&lt;/code&gt; with priority 30. &lt;code class=&quot;language-text&quot;&gt;wp_authenticate_cookie&lt;/code&gt; is not that we want to care about. &lt;code class=&quot;language-text&quot;&gt;It&amp;#39;s wp_authenticate_username_password&lt;/code&gt; that we need to deal with. So when you want to bypass this username and password combined authentication you basically need to bypass the execution of this function and return the user before it. So we’ll hook our own method to this filter with a priority less than 20 by the following line of code.&lt;/p&gt;
&lt;pre class=&quot;php&quot;&gt;
add_filter(&apos;authenticate&apos;,&apos;forceLogin&apos;,0,3);
&lt;/pre&gt;
&lt;p&gt;Now suppose you want to define an authentication that doesn’t really need a password, just write a function &lt;code class=&quot;language-text&quot;&gt;forceLogin()&lt;/code&gt; like the following.&lt;/p&gt;
&lt;pre class=&quot;php&quot;&gt;
function forceLogin($user,$username,$password)
{
  if(username_exists($username))
  {
    $user=get_user_by(&apos;login&apos;,$username);
    remove_action(&apos;authenticate&apos;, &apos;wp_authenticate_username_password&apos;, 20);
    return $user;
  }
}
&lt;/pre&gt;
&lt;p&gt;Thats it, now when you call the &lt;code class=&quot;language-text&quot;&gt;wp_signon()&lt;/code&gt; with just a username in the credentials, the user with the username in the credentials will be authenticated without actually requiring the password. Thats how its done. One can integrate OAuth and construct customized logins for their WordPress websites.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Setting up Eclipse as your C/C++ environment]]></title><description><![CDATA[Eclipse is an awesome and seemingly the best IDE when it comes to Android, Java and PHP development. Well, it becomes excrutiating when we…]]></description><link>https://ashishdubey.xyz/2011/05/05/eclipse-cpp-setup.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2011/05/05/eclipse-cpp-setup.html</guid><pubDate>Thu, 05 May 2011 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Eclipse is an awesome and seemingly the best IDE when it comes to Android, Java and PHP development. Well, it becomes excrutiating when we use an obsolete compiler for C/C++ or a compiler which is complicated as might be the case in a command line based gcc compiler. Talking about IDEs for C/C++, MS VC++ beats all odds, but then its beaten off by its own drawback of not being a cross-platform programming environment and being so Windows. This is where Eclipse starts ruling the stage. Eclipse being a highly flexible IDE, can support various developing languages and platforms, C/C++ not being among the exceptions. One can download the CDT plugin(c/c++ development tools) from the Eclipse’s website and integrate it with their Eclipse environment to start using Eclipse for C/C++ development. It uses the GNU based C tools to compile the code developed using c/c++ so make sure you have gcc installed in your computer. So I would just enlist the steps in brief to configure your Eclipse environment with CDT plugin.&lt;/p&gt;
&lt;p&gt;If you dont have Eclipse already installed, you can simply download the pre-configured IDE. &lt;a href=&quot;http://www.eclipse.org/downloads/packages/eclipse-ide-cc-developers/heliossr2&quot;&gt;Download Link&lt;/a&gt;
Otherwise,follow these steps,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Make sure you have gcc installed in your computer.&lt;/li&gt;
&lt;li&gt;Download the CDT plugin. &lt;a href=&quot;http://www.eclipse.org/downloads/packages/eclipse-ide-cc-developers/heliossr2&quot;&gt;Download Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Add your CDT plugin by going into Install New Software option that can be found in the help menu and browse the zip file of the CDT plugin that you downloaded.&lt;/li&gt;
&lt;li&gt;Thats it, start coding.&lt;/li&gt;
&lt;/ol&gt;</content:encoded></item><item><title><![CDATA[Socialize extension for Firefox]]></title><description><![CDATA[I just attended a boot-camp for extension development for Firefox, and got to say that Firefox is lot cooler than I ever thought. The boot…]]></description><link>https://ashishdubey.xyz/2011/04/18/socialize-ff-extension.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2011/04/18/socialize-ff-extension.html</guid><pubDate>Mon, 18 Apr 2011 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I just attended a boot-camp for extension development for Firefox, and got to say that Firefox is lot cooler than I ever thought. The boot-camp was organized by a group of open source developers in my college that comprised of the seniors from 2nd and 3rd year. It was all good, I enjoyed learning all the stuff related to extension development especially the new language XUL which is used to design extensions. One of the days included brainstorming of project ideas that we could implement our knowledge on. I had an idea of a social bookmarking/sharing plugin, so I thought I could give it a try. I trolled over and coded the extension throughout the night adding functionality to publish content on Facebook, StumbleUpon, Digg, and Twitter. The next day as the bootcamp concluded, I published my extension over the Mozilla’s add-on website. It can be found &lt;a href=&quot;https://addons.mozilla.org/en-US/firefox/addon/socialize-extension-for-fir&quot;&gt;here&lt;/a&gt;. If you use Firefox, I would be glad if you download it and give it a try and ofcourse comments and feedback is always welcome.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://opensource.jiitu.org/wiki/index.php?title=Socialize_Extension_for_Mozilla_Firefox&quot;&gt;Wiki page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://code.google.com/p/socialize-addon-firefox&quot;&gt;Google Project Hosting&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[The HTML Interpreter project]]></title><description><![CDATA[First semester in college marks the beginning of programming in more official terms than ever before. And with C language at the front, I…]]></description><link>https://ashishdubey.xyz/2010/12/07/html-interpreter.html</link><guid isPermaLink="false">https://ashishdubey.xyz/2010/12/07/html-interpreter.html</guid><pubDate>Tue, 07 Dec 2010 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;First semester in college marks the beginning of programming in more official terms than ever before. And with C language at the front, I cannot imagine it getting more official. It was a time when we were given introductory lectures on HTML. And it was this time that one of the lecturers talked about how a program would work that understands all the HTML code written and displays the web page accordingly and so beautifully or in coding an HTML browser.&lt;/p&gt;
&lt;p&gt;Well, on those terms I was well fascinated about making such a program in Visual Basic. But held on, the condition was developing it using C. While after then, some C lectures later, the first semester Mini-Project popped out into the scene and there I was, all setup with an idea to make a basic HTML Interpreter. The challenge wasn’t much of the C language, but lied in using the Windows API to create all sorts of Windows, formatting and displaying text and related stuff. Idea seemed clear, about how to read files and the structure of the same, and the mechanism of flagging text and displaying them according to the enclosing tags. These routines never had technical names until I read Internet Explorer Development references, and then I knew the process was called &lt;em&gt;Pre-Parsing&lt;/em&gt;. So I had my own Pre-parsing algorithm followed by a sort of messy text displaying mechanism using all kinds of fonts and text API functions of Win32 library. Text was done, when I thought about including image tag functionality in the same. BUT, already too big for the first semester?&lt;/p&gt;</content:encoded></item></channel></rss>